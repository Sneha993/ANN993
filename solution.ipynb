{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download dataset from link given below\n",
    "- images are stored in \"images\" folder and ground truth is stored in \"GroundTruth.csv\" file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle datasets download -d surajghuwalewala/ham1000-segmentation-and-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip -q ham1000-segmentation-and-classification.zip -d ham1000-segmentation-and-classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from torch.autograd import Variable\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#random seed\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.cuda.manual_seed(0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class customdataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,images_path,gt_path,transform=None):\n",
    "        self.root_dir=images_path\n",
    "        self.transform=transform\n",
    "        self.imgs = os.listdir(self.root_dir)\n",
    "        self.gt = pd.read_csv(gt_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)-2\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        label = self.gt.iloc[idx,1:].values\n",
    "        label = label.astype('float').reshape(-1,7)\n",
    "        name = self.gt.iloc[idx,0]\n",
    "        img_path = os.path.join(self.root_dir,name+'.jpg')\n",
    "        image = cv2.imread(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            label = torch.from_numpy(label)\n",
    "        return image,label\n",
    "\n",
    "\n",
    " \n",
    "data = customdataset(images_path='images',          # change this to the path where you have extracted the images\n",
    "                    gt_path='GroundTruth.csv',      # change this to the path where you have extracted the GroundTruth.csv\n",
    "                    transform=transforms.Compose(\n",
    "                        [transforms.ToTensor(),transforms.Resize((224,224)),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),\n",
    "                                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                    transforms.RandomVerticalFlip(p=0.5),\n",
    "                    transforms.RandomRotation(90),]))\n",
    "\n",
    "# Splitting the dataset into train and test into 80:20 ratio\n",
    "train_data, test_data = torch.utils.data.random_split(data, [int(0.8*len(data)), len(data)-int(0.8*len(data))])\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 9, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(9, 18, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(18, 36, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(28224, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 7)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# train the model for 14 epochs\n",
    "for epoch in range(14):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        labels = labels.view(-1, 7)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if i % 20 == 9:    # print every 20 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "torch.save(model.state_dict(), 'model+14.pth')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          nv       0.57      0.39      0.47       223\n",
      "         mel       0.86      0.93      0.89      1358\n",
      "         bkl       0.52      0.57      0.55        95\n",
      "         bcc       0.40      0.41      0.41        76\n",
      "       akiec       0.53      0.47      0.50       208\n",
      "        vasc       0.17      0.04      0.06        25\n",
      "          df       0.75      0.33      0.46        18\n",
      "\n",
      "    accuracy                           0.77      2003\n",
      "   macro avg       0.54      0.45      0.48      2003\n",
      "weighted avg       0.75      0.77      0.75      2003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plot_labels = ['MEL','NV','BCC','AKIEC','BKL','DF','VASC']\n",
    "model.eval()\n",
    "y_label = []\n",
    "y_predict = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_loader):\n",
    "        images, labels = data\n",
    "        labels = labels.view(-1, 7)\n",
    "        N = images.size(0)\n",
    "        images = Variable(images).to(device)\n",
    "        gt = torch.argmax(labels.data, 1)\n",
    "        outputs = model(images)\n",
    "        prediction = outputs.max(1, keepdim=True)[1]\n",
    "        y_label.extend(gt.cpu().numpy())\n",
    "        y_predict.extend(np.squeeze(prediction.cpu().numpy().T))\n",
    "\n",
    "all_metrics = classification_report(y_label, y_predict, target_names=plot_labels,zero_division=0)\n",
    "print(all_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.78%\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_label, y_predict)\n",
    "print('Accuracy: {:.2f}%'.format(acc*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a15b9ed3e3cb3fe34dfdb40f0e5d4860e67d4b818b63d6e4be77733bd115c760"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
